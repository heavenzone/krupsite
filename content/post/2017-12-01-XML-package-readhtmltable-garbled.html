---
title: 关于XML包readHTMLTable乱码
author: Heaven Zone
date: '2017-12-01'
slug: XML-package-readhtmltable-garbled
categories:
  - R
tags:
  - R
  - XML
  - readHTMLTable
description: 'readHTMLTable乱码怎么解决呢？'
---



<div class="section level2">
<h2>目的</h2>
<p>现在要爬p2peye的页面http://www.p2peye.com/shuju/ptsj/ ，R的XML包的readHTMLTable函数提供了非常方便的读取网页表格的方法。</p>
</div>
<div id="readhtmltable" class="section level2">
<h2>用readHTMLTable</h2>
<p>说干就干，马上调出readHTMLTable。</p>
<pre class="r"><code>library(XML)
url = &quot;http://www.p2peye.com/shuju/ptsj/&quot;
p2ptable = readHTMLTable(url, header = FALSE, stringsAsFactors = F)
head(p2ptable[[&quot;platdata&quot;]][,1:3])</code></pre>
<pre><code>##   V1                       V2             V3
## 1  1  寰捶缃&lt;U+393C&gt;&lt;U+3E31&gt; 39830.25涓\x87
## 2  2       瀹滀汉璐戼&lt;U+3E37&gt; 19817.89涓\x87
## 3  3       浣犳垜璐戼&lt;U+3E37&gt; 17598.82涓\x87
## 4  4 鐖遍挶杩&lt;U+393C&gt;&lt;U+3E62&gt; 13939.45涓\x87
## 5  5             灏忕墰鍦ㄧ嚎 13220.18涓\x87
## 6  6       缈奸緳璐戼&lt;U+3E37&gt; 11440.71涓\x87</code></pre>
<p>表格读取到了，但是出现乱码了。</p>
</div>
<div id="geturl" class="section level2">
<h2>用getURL</h2>
<p>在这里直接导入四个跟爬虫有关的包XML、xml2、RCurl和rvest，因为我真的是记不住那些函数究竟是哪个包里面的了。</p>
<p>搜了很多网站去查询关于抓网页出现乱码的问题，国内国外，很多情况都喜欢在readHTMLTable前用getURL弄一下设置一下encoding，ok，我们试一下吧。</p>
<p>我们查看了该网页的源代码是有一个<code>charset=gbk</code>的设置，因此我们把encoding设置成了gbk：</p>
<pre class="r"><code>require(xml2)
require(XML)
require(RCurl)
require(rvest)
url = &quot;http://www.p2peye.com/shuju/ptsj/&quot;
p2ptable &lt;- getURL(url, .encoding = &quot;UTF-8&quot;)
p2ptable = readHTMLTable(p2ptable, header = FALSE, stringsAsFactors = F)
head(p2ptable[[&quot;platdata&quot;]][,1:3])</code></pre>
<pre><code>##   V1                       V2             V3
## 1  1  寰捶缃&lt;U+393C&gt;&lt;U+3E31&gt; 39830.25涓\x87
## 2  2       瀹滀汉璐戼&lt;U+3E37&gt; 19817.89涓\x87
## 3  3       浣犳垜璐戼&lt;U+3E37&gt; 17598.82涓\x87
## 4  4 鐖遍挶杩&lt;U+393C&gt;&lt;U+3E62&gt; 13939.45涓\x87
## 5  5             灏忕墰鍦ㄧ嚎 13220.18涓\x87
## 6  6       缈奸緳璐戼&lt;U+3E37&gt; 11440.71涓\x87</code></pre>
<p>还是出现乱码。</p>
<p>尝试把gbk更改为UTF-8也是一样的乱码。</p>
<p>国外一些有人也喜欢用readLines代替getURL，所以也尝试了将上面这行代码：</p>
<pre class="r"><code>p2ptable &lt;- getURL(url, .encoding = &quot;UTF-8&quot;)</code></pre>
<p>改为</p>
<pre class="r"><code>p2ptable = readLines(url, encoding = &quot;UTF-8&quot;)</code></pre>
<p>结果还是乱码。</p>
</div>
<div class="section level2">
<h2>一些测试</h2>
<div id="htmlparse" class="section level3">
<h3>测试htmlParse</h3>
<pre class="r"><code>htmlParse(url, encoding = &quot;gbk&quot;)
htmlParse(url, encoding = &quot;UTF-8&quot;)</code></pre>
<p>上面两个代码得到的结果都是乱码。</p>
</div>
<div id="geturl" class="section level3">
<h3>测试getURL</h3>
<pre class="r"><code>getURL(url, .encoding = &quot;gbk&quot;)</code></pre>
<p>用getURL，并设置好参数<code>.encoding = &quot;gbk&quot;</code>，得到的<strong>没有乱码</strong>。</p>
<pre class="r"><code>getURL(url, .encoding = &quot;UTF-8&quot;)</code></pre>
<p>如果<code>.encoding</code>设置成<code>UTF-8</code>得到的结果乱码。</p>
<p>说明getURL可以通过设置encoding来避免出现乱码，但是前面的测试结果显示，就算getURL可以得到正常的结果，但是通过readHTMLTable读取getURL的结果仍然是出现乱码。</p>
</div>
</div>
<div id="linuxreadhtmltable" class="section level2">
<h2>linux下的readHTMLTable没有乱码问题</h2>
<p>完全一样的代码，我在linux系统manjaro-i3（locale当然是UTF-8的）上用，测试下面这段代码，就没有出现乱码。</p>
<pre class="r"><code>library(XML)
url = &quot;http://www.p2peye.com/shuju/ptsj/&quot;
p2ptable = readHTMLTable(url, header = FALSE, stringsAsFactors = F)
head(p2ptable[[&quot;platdata&quot;]][,1:3])</code></pre>
<pre><code>##   V1                       V2             V3
## 1  1  寰捶缃&lt;U+393C&gt;&lt;U+3E31&gt; 39830.25涓\x87
## 2  2       瀹滀汉璐戼&lt;U+3E37&gt; 19817.89涓\x87
## 3  3       浣犳垜璐戼&lt;U+3E37&gt; 17598.82涓\x87
## 4  4 鐖遍挶杩&lt;U+393C&gt;&lt;U+3E62&gt; 13939.45涓\x87
## 5  5             灏忕墰鍦ㄧ嚎 13220.18涓\x87
## 6  6       缈奸緳璐戼&lt;U+3E37&gt; 11440.71涓\x87</code></pre>
<p>难道就如<a href="http://www.dataguru.cn/thread-567670-1-1.html">这里</a>所说的？</p>
<blockquote>
<p>你这个是在windows系统下抓取的吧？XML在windows系统下不能很好的处理中文</p>
</blockquote>
<p>或者如<a href="http://blog.csdn.net/BieberSen/article/details/50789702">这里</a>所说？</p>
<blockquote>
<p>如果HTML中本身已经指定了编码（此处就是，但是有2个charset。。。前一个是GB2312，后一个是UTF-8），那么就会 强制 使用HTML中内部指定的编码而忽略调用者（此处我们的代码所传入的GBK）</p>
<p>所以即使调用者指定了正确的HTML的编码，结果也还是使用HTML内部自己所指定的错误的编码（此处应该就是用了第二个charset，即UTF-8来解析的）从而导致乱码的。</p>
<p>差不多算是一个bug吧</p>
</blockquote>
</div>
<div class="section level2">
<h2>小结</h2>
<p>简单做一个小结，我们上面一共用到了readHTMLTable、getURL、htmlParse这三个函数，看看他们属于哪个包？</p>
<ul>
<li>XML::readHTMLTable()</li>
<li>XML::htmlParse</li>
<li>RCurl::getURL()</li>
</ul>
<p>难道真的如前面两个网站所说的？XML在windows系统下不能很好的处理中文？或者这是一个bug？</p>
<p>不过我们还是有另外一个包可以处理。</p>
</div>
<div class="section level2">
<h2>最终解决乱码的办法</h2>
<p>不过最终我们还是有办法处理这个问题，也是能够像readHTMLTable一样的方便直接读取表格数据。</p>
<p>这次我们用到了<strong>rvest</strong>的html_table函数和<strong>xml2</strong>的read_html函数。</p>
<pre class="r"><code>library(&quot;rvest&quot;)
webpage &lt;- read_html(url, fill = TRUE)
webpage.table &lt;- html_table(webpage)
head(webpage.table[[2]][2:5])</code></pre>
<pre><code>##         X2         X3     X4      X5
## 1   微贷网 39830.25万  7.56% 14762人
## 2   宜人贷 19817.89万 11.79% 95655人
## 3   你我贷 17598.82万 10.81% 41565人
## 4   爱钱进 13939.45万  10.3% 10360人
## 5 小牛在线 13220.18万  9.47% 16428人
## 6   翼龙贷 11440.71万  9.81% 13066人</code></pre>
<p>当然我们也可以用到<strong>rvest</strong>的<strong>html_nodes</strong>会更方便，如果该网页有多个table表格，那么就可以直接用css来定位要获取的表格，下面练习了一下<code>%&gt;%</code>的方式来写代码。</p>
<pre class="r"><code>webpage.table2 &lt;- url %&gt;%
  read_html() %&gt;%
  html_nodes(css =&#39;#platdata&#39;) %&gt;%
  html_table() %&gt;% .[[1]]
webpage.table2 %&gt;% .[1:4] %&gt;% head</code></pre>
<pre><code>##   X1       X2         X3     X4
## 1  1   微贷网 39830.25万  7.56%
## 2  2   宜人贷 19817.89万 11.79%
## 3  3   你我贷 17598.82万 10.81%
## 4  4   爱钱进 13939.45万  10.3%
## 5  5 小牛在线 13220.18万  9.47%
## 6  6   翼龙贷 11440.71万  9.81%</code></pre>
<p>结果就是我们想要的，中国人能读的中文了。</p>
</div>
<div class="section level2">
<h2>参考资料</h2>
<ul>
<li><a href="https://stackoverflow.com/questions/1395528/scraping-html-tables-into-r-data-frames-using-the-xml-package">Scraping html tables into R data frames using the XML package</a></li>
<li><a href="https://www.r-bloggers.com/using-rvest-to-scrape-an-html-table/">Using rvest to Scrape an HTML Table</a></li>
<li><a href="http://www.dataguru.cn/thread-567670-1-1.html">如何处理readHTMLTable函数抓取乱码数据</a></li>
<li><a href="http://blog.csdn.net/BieberSen/article/details/50789702">使用RCurl爬虫爬取网页内容htmlParse解析时出现乱码</a></li>
<li><a href="https://www.crifan.com/try_use_r_language_do_web_crawl_and_extract_info/">【记录】尝试用R语言去抓取网页和提取信息</a></li>
</ul>
</div>
